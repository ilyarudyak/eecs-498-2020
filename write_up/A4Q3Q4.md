## Q3 - network visualization

All 3 questions are using a backward pass. Forward pass is used only for illustration purposes in lectures. But we use it in a different way: number of passes can be different as well as the initial image ans so on:

| question             | initial image | ## of passes | loss                  | regularization | 
| -------------------- | ------------- | ------------ | --------------------- | -------------- |
| saliency maps        | actual image  | single       | cross-entropy         | none           | 
| adversarial attack   | actual image  | multiple     | score of target class | none           |
| class visualization  | empty image   | multiple     | correct score         | l2             |

In all cases we use  gradient *ascent* which means we *increase* the value of a variable by a gradient (not *decrease* it as usual). We should use an appropriate scope and remove accumulated gradients as specified in this [tutorial](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_autograd.html).

### 01 - saliency maps
- there's no optimization problem - we just run a single pass of a gradient ascent (which makes it pretty quick); why does it work?

> In this case (a linear model), it is easy to see that the magnitude of elements of `w` defines the importance of the corresponding pixels of `I` for the class `c`. ... given an image `I0`, we can approximate `Sc(I)` with a linear function in the neighbourhood of `I0` by computing the first-order Taylor expansion.

> Another interpretation of computing the image-specific class saliency using the class score derivative (4) is that the magnitude of the derivative indicates which pixels need to be changed the least to affect the class score the most.

- it's not quite clear from the paper what should we backpropagate - class scores or cross-entropy loss; it seems that cross-entropy loss will give us pretty good saliency maps;

### 02 - adversarial attack
- it's quite easy to fool a model and it's not stable at all:

> For all the networks we studied (MNIST, QuocNet [10], AlexNet [9]), for each sample, we have always managed to generate very close, visually hard to distinguish, ad- versarial examples that are misclassified by the original network.

- the **optimization problem**: `max Sc(I)` over `I` where `c` is a target class; so we run gradient ascent trying to maximize the target (adversarial) class on the provided image; 
- we use an actual image (for example an image of a schoolbus) and construct and adversarial image; it visually looks like exactly the same but the model gives us the different (adversarial) class (for example an ostrich);
- we run the backward pass until the model is fooled; the number of iterations is usually quite small (10-20); it's better to run a few iterations (2-3) after the target class is reached to get a stable result;
- we should use normalized gradient;

### 03 - class visualization
- the main idea - we may reconstruct an image (which is going to look like a deep dream image) that the model classifies as a given class:

> The procedure is related to the ConvNet training procedure, where the back-propagation is used to optimise the layer weights. The difference is that in our case the optimisation is performed with respect to the input image, while the weights are fixed to those found during the training stage.

- the **optimization problem**: `max Sc(I) + l2` over `I` starting from an empty image; 
- we backpropagate from a class score rather than from softmax probability:

> The reason is that the maximization of the class posterior can be achieved by minimising the scores of other classes. Therefore, we optimise `Sc` to ensure that the optimisation concentrates only on the class in question `c`. 

## Q4 - style transfer
There are 3 main ideas behind style transfer: 
- first of all we may construct an image using backprop like before; 

> To visualise the image information that is encoded at
different layers of the hierarchy one can perform gradient descent on a white noise image to find another image that matches the feature responses of the original image (Fig 1, content reconstructions) [24].

- the key idea - we may extract content and style from an image *separately*: to extract content we may use feature maps from upper convolutional layers; to extract style we have to use a covariance matrix of features (Gram matrix); 

> We therefore refer to the feature responses in higher layers of the network as the content representation. To obtain a representation of the style of an input image, we use a feature space designed to capture texture information [10].


- so we extract content from one image and style from another; we have 2 loss functions for backprop and we may combine them (in the paper they combine them with some coefficients, in the assignment we just use sum of them);

> Thus we jointly minimise the distance of the feature representations of a white noise image from the content representation of the photograph in one layer and the style representation of the painting defined on a number of layers of the Convolutional Neural Network.